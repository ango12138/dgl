{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/huangqi/dgl2/dgl/python/dgl/graph.py:657: UserWarning: to_networkx currently does not support converting node/edge features automatically.\n",
      "  dgl_warning('to_networkx currently does not support converting'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train is 21\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import binary_sub_graph as bsg\n",
    "\n",
    "data = citegrh.load_cora()\n",
    "\n",
    "trainingset = bsg.CORABinary(DGLGraph(data.graph), data.features, data.labels, num_classes=7)\n",
    "\n",
    "num_train = len(trainingset)\n",
    "print(\"num_train is\", num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "n_batch_size = 1\n",
    "split = 20\n",
    "\n",
    "indices = list(range(num_train))\n",
    "training_loader = DataLoader(trainingset, \n",
    "                             n_batch_size,\n",
    "                             collate_fn=trainingset.collate_fn, \n",
    "                             drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6994106090373281, 1: 0.7949465500485908, 2: 0.9058050383351588, 3: 0.8280479210711769, 4: 0.8291457286432161, 5: 0.7679558011049724, 6: 0.7689969604863222}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/huangqi/dgl2/dgl/python/dgl/graph.py:657: UserWarning: to_networkx currently does not support converting node/edge features automatically.\n",
      "  dgl_warning('to_networkx currently does not support converting'\n"
     ]
    }
   ],
   "source": [
    "# We first validate that in CORA, intra community connections\n",
    "# are more than inter community connections\n",
    "\n",
    "g_nx = DGLGraph(data.graph).to_networkx()\n",
    "adj = nx.adjacency_matrix(g_nx).todense()\n",
    "class_to_intra_prob = {i: 0 for i in range(7)}\n",
    "class_to_total = {i: 0 for i in range(7)}\n",
    "class_to_intra_sum = {i: 0 for i in range(7)}\n",
    "for i in range(g_nx.number_of_nodes()):\n",
    "    _, index = np.where(adj[i] !=0)\n",
    "    each_total = len(index)\n",
    "    intra_num = 0\n",
    "    for j in index:\n",
    "        if data.labels[i] == data.labels[j]:\n",
    "            intra_num += 1\n",
    "    class_to_total[int(data.labels[i])] += each_total\n",
    "    class_to_intra_sum[int(data.labels[i])] += intra_num\n",
    "for i in range(7):\n",
    "    class_to_intra_prob[i] = class_to_intra_sum[i] / class_to_total[i]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(class_to_intra_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#CORA visualization tool\n",
    "def cora_viz(labels,subgraph):\n",
    "    value = [labels[node] for node in subgraph.nodes()]\n",
    "    pos = nx.spring_layout(subgraph, random_state=1)\n",
    "    nx.draw_networkx(subgraph, \n",
    "                     pos=pos, \n",
    "                     edge_color='k', \n",
    "                     node_size=5, \n",
    "                     cmap=plt.get_cmap('Set2'), \n",
    "                     node_color=value,\n",
    "                     arrows=False,\n",
    "                     width=0.6,\n",
    "                     with_labels=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------Model--------------------------------\n",
    "class GNNModule(nn.Module):\n",
    "    def __init__(self, in_feats, in_y_feats, out_feats, radius):\n",
    "        super().__init__()\n",
    "        self.out_feats = out_feats\n",
    "        self.radius = radius\n",
    "\n",
    "        new_linear = lambda: nn.Linear(in_feats, out_feats)\n",
    "        new_linear_list = lambda: nn.ModuleList([new_linear() for i in range(radius)])\n",
    "        \n",
    "        new_linear_y = lambda: nn.Linear(in_y_feats, out_feats)\n",
    "        new_linear_list_y = lambda: nn.ModuleList([new_linear_y() for i in range(radius)])\n",
    "        self.theta_x, self.theta_deg = \\\n",
    "            new_linear(), new_linear()\n",
    "        self.theta_y = new_linear_y()\n",
    "        self.theta_list = new_linear_list()\n",
    "\n",
    "        self.gamma_deg, self.gamma_x = \\\n",
    "            new_linear_y(), new_linear()\n",
    "        self.gamma_y = new_linear_y()\n",
    "        self.gamma_list = new_linear_list_y()\n",
    "\n",
    "        self.bn_x = nn.BatchNorm1d(out_feats)\n",
    "        self.bn_y = nn.BatchNorm1d(out_feats)\n",
    "\n",
    "    def aggregate(self, g, z):\n",
    "        z_list = []\n",
    "        g.ndata['z'] = z \n",
    "        g.update_all(fn.copy_src(src='z', out='m'), fn.sum(msg='m', out='z'))\n",
    "        z_list.append(g.ndata['z'])\n",
    "        for i in range(self.radius - 1):\n",
    "            for j in range(2 ** i):\n",
    "                g.update_all(fn.copy_src(src='z', out='m'), fn.sum(msg='m', out='z'))\n",
    "            z_list.append(g.ndata['z'])\n",
    "        return z_list\n",
    "\n",
    "    def forward(self, g, lg, x, y, deg_g, deg_lg, pm_pd):\n",
    "        pmpd_x = F.embedding(pm_pd, x)\n",
    "\n",
    "        sum_x = sum(theta(z) for theta, z in zip(self.theta_list, self.aggregate(g, x)))\n",
    "        \n",
    "        g.edata['y'] = y\n",
    "        g.update_all(fn.copy_edge(edge='y', out='m'), fn.sum('m', 'pmpd_y'))\n",
    "        pmpd_y = g.pop_n_repr('pmpd_y')\n",
    "\n",
    "        x = self.theta_x(x) + self.theta_deg(deg_g * x) + sum_x + self.theta_y(pmpd_y)\n",
    "        n = self.out_feats // 2\n",
    "        x = th.cat([x[:, :n], F.relu(x[:, n:])], 1)\n",
    "        x = self.bn_x(x)\n",
    "\n",
    "        sum_y = sum(gamma(z) for gamma, z in zip(self.gamma_list, self.aggregate(lg, y)))\n",
    "        y = self.gamma_y(y) + self.gamma_deg(deg_lg * y) + sum_y + self.gamma_x(pmpd_x)\n",
    "        \n",
    "        y = th.cat([y[:, :n], F.relu(y[:, n:])], 1)\n",
    "        y = self.bn_y(y)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, feats, radius, n_classes):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : networkx.DiGraph\n",
    "        \"\"\"\n",
    "        super(GNN, self).__init__()\n",
    "        self.linear = nn.Linear(feats[-1], n_classes)\n",
    "        self.y_feats = [1] + feats[1:]\n",
    "        self.module_list = nn.ModuleList([GNNModule(m, m_y, n, radius)\n",
    "                                          for m, m_y, n in zip(feats[:-1],self.y_feats[:-1], feats[1:])])\n",
    "\n",
    "    def forward(self, g, lg, deg_g, deg_lg, pm_pd, feature):\n",
    "        x, y = feature, deg_lg\n",
    "        for module in self.module_list:\n",
    "            x, y = module(g, lg, x, y, deg_g, deg_lg, pm_pd)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(z_list, labels):\n",
    "    accu = []\n",
    "    ybar_list = [th.max(z, 1)[1] for z in z_list]\n",
    "    for y_bar in ybar_list:\n",
    "        accuracy = max(th.sum(y_bar == label).item() for label in labels) / len(labels[0])\n",
    "        accu.append(accuracy)\n",
    "    return sum(accu) / len(accu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def step(i, j, g, lg, deg_g, deg_lg, pm_pd, feature, label, equi_label, n_batchsize):\n",
    "    \"\"\" One step of training. \"\"\"\n",
    "    t0 = time.time()\n",
    "    z = model(g, lg, deg_g, deg_lg, pm_pd, feature)\n",
    "    time_forward = time.time() - t0\n",
    "\n",
    "    z_list = th.chunk(z, n_batchsize, 0)\n",
    "    equi_labels = [label, equi_label]\n",
    "    loss = sum(min(F.cross_entropy(z, y) for y in equi_labels) for z in z_list) / n_batchsize\n",
    "    \n",
    "    accu = accuracy(z_list, equi_labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    t0 = time.time()\n",
    "    loss.backward()\n",
    "    time_backward = time.time() - t0\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, accu, time_forward, time_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(g, lg, deg_g, deg_lg, pm_pd, feature, label, equi_label):\n",
    "    z = model(g, lg, deg_g, deg_lg, pm_pd, feature)\n",
    "    \n",
    "    z_list = [z]\n",
    "    \n",
    "    equi_labels = [label, equi_label]\n",
    "    \n",
    "    accu = accuracy(z_list, equi_labels)\n",
    "    \n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_viz(g, lg, deg_g, deg_lg, pm_pd, feature):\n",
    "    z = model(g, lg, deg_g, deg_lg, pm_pd, feature)\n",
    "    \n",
    "    z_list = [z]\n",
    "    \n",
    "    n_batchsize = 1\n",
    "    ybar_list = [th.max(z, 1)[1] for z in z_list]\n",
    "    cora_viz(ybar_list[0],g.to_networkx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "n_features = 16\n",
    "n_layers = 2\n",
    "radius = 1\n",
    "lr = 1e-2\n",
    "K = 2 # num_of_classes\n",
    "inference_idx = 8\n",
    "feats = [data.features.shape[1]] + [n_features]*n_layers + [K]\n",
    "model = GNN(feats, radius, K)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss for epoch 0 is 0.6487789154052734, with avg accu 0.6728866997866897, forward time 2.80676007270813, backward time 1.3527443408966064\n",
      "average loss for epoch 1 is 0.5731345415115356, with avg accu 0.734185096620451, forward time 2.7366836071014404, backward time 1.4635064601898193\n",
      "average loss for epoch 2 is 0.5186848640441895, with avg accu 0.7670205854618576, forward time 2.2783265113830566, backward time 1.2068977355957031\n",
      "average loss for epoch 3 is 0.4826054871082306, with avg accu 0.7672132042708076, forward time 2.8350391387939453, backward time 1.6086928844451904\n",
      "average loss for epoch 4 is 0.41519400477409363, with avg accu 0.8228094789433474, forward time 2.643474817276001, backward time 1.131606101989746\n",
      "average loss for epoch 5 is 0.3930448293685913, with avg accu 0.8204643626402457, forward time 3.3735711574554443, backward time 2.3382842540740967\n"
     ]
    }
   ],
   "source": [
    "#main loop\n",
    "\n",
    "\n",
    "\n",
    "n_iterations = 20\n",
    "n_epochs = 10\n",
    "validation_example_label_change = []\n",
    "total_time = 0\n",
    "for i in range(n_epochs):\n",
    "    total_loss, total_accu, s_forward, s_backward = 0, 0, 0, 0\n",
    "    for j, [g, lg, g_deg, lg_deg, pm_pd, subfeature, label, equivariant_label] in enumerate(training_loader):\n",
    "        loss, accu, t_forward, t_backward = step(i,\n",
    "                                                 j,\n",
    "                                                 g,\n",
    "                                                 lg,\n",
    "                                                 th.FloatTensor(g_deg),\n",
    "                                                 th.FloatTensor(lg_deg),\n",
    "                                                 th.LongTensor(pm_pd),\n",
    "                                                 th.FloatTensor(subfeature),\n",
    "                                                 th.LongTensor(label),\n",
    "                                                 th.LongTensor(equivariant_label),\n",
    "                                                 n_batch_size)\n",
    "        total_loss += loss\n",
    "        s_forward += t_forward\n",
    "        s_backward += t_backward\n",
    "        total_accu += accu\n",
    "    total_time += (s_forward + s_backward)\n",
    "    \n",
    "    print(\"average loss for epoch {} is {}, with avg accu {}, forward time {}, backward time {}\".format(i, total_loss/len(training_loader), total_accu/len(training_loader), s_forward, s_backward))\n",
    "    [g, lg, g_deg, lg_deg, pm_pd, subfeature, label, equi_label] = trainingset[inference_idx]    \n",
    "    z = model(g,\n",
    "              lg, \n",
    "              th.FloatTensor(g_deg), \n",
    "              th.FloatTensor(lg_deg), \n",
    "              th.LongTensor(pm_pd), \n",
    "              th.FloatTensor(subfeature))\n",
    "    validation_example_label_change.append(th.max(z, 1)[1])\n",
    "print(\"total time {} s, average {}\".format(total_time, total_time/n_iterations))\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"inference on one training example...\")\n",
    "for k in range(len(training_loader) - split):\n",
    "    [g, lg, g_deg, lg_deg, pm_pd, subfeature, label, equi_label] = trainingset[inference_idx]\n",
    "    accu = val(g, \n",
    "               lg, \n",
    "               th.FloatTensor(g_deg), \n",
    "               th.FloatTensor(lg_deg), \n",
    "               th.LongTensor(pm_pd), \n",
    "               th.FloatTensor(subfeature),\n",
    "               th.LongTensor(label),\n",
    "               th.LongTensor(equi_label))\n",
    "    print(\"#########\")\n",
    "    print(\"inference accu {}\".format(accu))\n",
    "    print(\"#########\")\n",
    "    inference_viz(g,\n",
    "                  lg,\n",
    "                  th.FloatTensor(g_deg),\n",
    "                  th.FloatTensor(lg_deg),\n",
    "                  th.LongTensor(pm_pd),\n",
    "                  th.FloatTensor(subfeature))\n",
    "    plt.show()\n",
    "    cora_viz(label, g.to_networkx())\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.ones(3)\n",
    "y = th.ones(4)\n",
    "th.cat([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cora_viz_ani(labels,subgraph):\n",
    "    value = [labels[node] for node in subgraph.nodes()]\n",
    "    pos = nx.spring_layout(subgraph, random_state=1)\n",
    "    nx.draw_networkx(subgraph, \n",
    "                     pos=pos, \n",
    "                     edge_color='k', \n",
    "                     node_size=5, \n",
    "                     cmap=plt.get_cmap('Set2'), \n",
    "                     node_color=value,\n",
    "                     with_labels=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(8,8), dpi=150)\n",
    "fig2.clf()\n",
    "ax = fig2.subplots()\n",
    "[g, lg, g_deg, lg_deg, pm_pd, subfeature, label, equi_label] = trainingset[inference_idx]\n",
    "g_nx = g.to_networkx()\n",
    "pos = nx.spring_layout(g_nx, random_state=1)\n",
    "\n",
    "def classify_animate(i):\n",
    "    ax.cla()\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"community detection result @ epoch %d\" % i)\n",
    "    value = [validation_example_label_change[i][node] for node in g_nx.nodes()]\n",
    "    nx.draw_networkx(g_nx,\n",
    "                     pos=pos,\n",
    "                     edge_color='k',\n",
    "                     node_size=7,\n",
    "                     cmap=plt.get_cmap('Set2'),\n",
    "                     node_color=value,\n",
    "                     arrows=False,\n",
    "                     width=0.6,\n",
    "                     with_labels=False)\n",
    "    \n",
    "\n",
    "ani = animation.FuncAnimation(fig2, classify_animate, frames=len(validation_example_label_change), interval=500)\n",
    "ani.save('./animationnew.gif', writer='imagemagick')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toygraph = DGLGraph()\n",
    "toygraph.add_nodes(4)\n",
    "toygraph.add_edges([0,1,1,0,3,3,2],[1,0,2,3,2,0,0])\n",
    "nx.draw(toygraph.to_networkx(), with_labels=True)\n",
    "lg = toygraph.line_graph(backtracking=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(lg.to_networkx(), with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
